\chapter{Complex calculus}
\label{h:complex}

\begin{quote}
The shortest path between two truths in the real domain passes through the complex domain.

--- Jacques Hadamard
\end{quote}

\begin{quote}
The imaginary number is a fine and wonderful recourse of the divine spirit, almost an amphibian between being and not being.

--- Gottfried Wilhelm Leibniz
\end{quote}

\begin{quote}
  Life is complex: it has both real and imaginary components.
  
--- Rich Rosen
\end{quote}

\chaptertoc

In this chapter, we will discuss the basic principles of complex analysis and its applications.

We will define functions of a complex variable and show how to differentiate and integrate them. In order to facilitate the calculation of integrals, residue calculus is introduced. This will give us a powerful tool to also calculate some real-valued integrals in a much more straightforward way. Finally, we discuss conformal transformations as a way to map problems to equivalent ones having an 'easier' geometry. 

We will also study a number of direct applications of complex analysis, e.g. the Kramers--Kronig dispersion relations, and the use of conformal transformations to model waveguide bends.



\pagebreak


\sectionyoutubeugent{Functions of a complex variable}{RLUN39pdXFA}

A function of a complex variable is simply defined as

\begin{equation}
f(z) \stackrel{def}{=} f(x + j y) \stackrel{def}{=}  u(x,y) + j v(x,y)
\end{equation}

Here, $u$ and $v$ are two real--valued functions of $x$ and $y$. Unsurprisingly, we call $u$ the real part of $f$ and $v$ the imaginary part of $f$.

\begin{cue}
Take
$$u = x^2 - y^2$$
$$v = 2 x y$$
What is $f(z)$?
\end{cue}

In this case,

$$f(z) = u + j v = x^2 - y^2 +2j x y = (x + jy)^2$$

So, formally we can say that $u$ and $v$ define the function $f(z) = z^2$

\begin{cue}
Given
$$f(z) = z z^* $$

What are the corresponding $u$ and $v$?
\end{cue}

We have 
$$f(z) = (x + jy)(x - jy) = x^2 + y^2$$

So, the real and imaginary parts are:

$$u = x^2 + y^2$$
$$v = 0$$


\pagebreak


\sectionugent{Derivative of a complex function}

\subsectionyoutube{Definition}{h6s2itfipks}

Let us now differentiate complex functions. In analogy with real--valued functions, we would like to define the complex derivative as

\begin{equation}
f' (z)=\frac{df}{dz} \stackrel{def}{=} \lim_{\Delta z \to 0} \frac{f(z+\Delta z) - f(z)}{z+\Delta z - z} \label{eq-deriv}
\end{equation} 

\begin{cue}
Use this definition to find the derivative of $f(z)=z^2$.
\end{cue}

To calculate the derivative of  $f(z)=z^2$, we find that

$$f'(z)=\lim_{\Delta z \to 0} \frac{(z+\Delta z)^2 - z^2}{\Delta z} = \lim_{\Delta z \to 0} \frac{2 z \Delta z + (\Delta z)^2}{\Delta z}=2z $$

This gives the same result as in the real-valued case.

At this point, you might wonder what all the fuss is about, as complex analysis seems to boil down to simply replacing $x$ by $z$. However, there's more going on than meets the eye.

\begin{cue}
Try to find the derivative of $f(z)=|z|^2$.
\end{cue}

In this case, we get

$$f'(z)=\lim_{\Delta z \to 0} \frac{|z+\Delta z|^2 - |z|^2}{\Delta z} $$

The numerator is obviously real-valued, but the denominator is in general complex, so that the result of this operation would depend on the direction of approach encoded in $\Delta z$.

This is obviously undesirable. Now, we can ask ourself the question, what are the conditions under which the derivative Eq.~\ref{eq-deriv} of a complex function is independent of the direction of approach?

\pagebreak

\subsectionyoutube{The Cauchy-Riemann conditions are necessary}{nmPsFdM4gu4}

\begin{marginfigure}[0cm]
\includegraphics[width=4cm]{complex/figures/approach_z}
\caption{Different approaches to $z$ in the complex plane.}
\label{fig-approach-z}
\end{marginfigure}

Let's have a look at the necessary conditions first. If the direction of approach does not matter at all, then we should certainly get the same result if we pick two special directions (see Fig.~\ref{fig-approach-z}).

\begin{cue}
By splitting both $f$ and $z$ into their real and imaginary components, take the limit of $\Delta f / \Delta z$ along the horizontal direction.
\end{cue}

Along the horizontal direction, $\Delta y = 0$, so taking the limit $\Delta x \to 0$, we get

\begin{align}
\lim_{\Delta z \to 0} \frac{\Delta f}{\Delta z}
& = \lim_{\Delta z \to 0} \frac{\Delta u + j \Delta v}{\Delta x + j \Delta y}
\nonumber \\
& = \lim_{\Delta x \to 0} \frac{\Delta u}{\Delta x} + j \frac{\Delta v}{\Delta
x} \nonumber \\
& = \frac{\partial u}{\partial x} + j \frac{\partial v}{\partial
x}\label{eq-deriv-dx}
\end{align} 

\begin{cue}
Do the same for an approach along the vertical direction.
\end{cue}

Along the vertical direction, $\Delta x = 0$ and we should take the limit $\Delta y \to 0$:

\begin{align}
\lim_{\Delta z \to 0} \frac{\Delta f}{\Delta z}
& = \lim_{\Delta z \to 0} \frac{\Delta u + j \Delta v}{\Delta x + j \Delta y}
\nonumber \\
& = \lim_{\Delta y \to 0} -j\frac{\Delta u}{\Delta y} +  \frac{\Delta v}{\Delta
y} \nonumber \\
& = -j\frac{\partial u}{\partial y} +  \frac{\partial v}{\partial
y}\label{eq-deriv-dy}
\end{align}

\begin{cue}
Now derive a necessary condition for the complex derivative to be independent of the direction of approach.
\end{cue}

A necessary condition for the complex derivative to be independent of the direction of approach, can be derived from equating the real and imaginary parts of Eq.~\ref{eq-deriv-dx} and \ref{eq-deriv-dy}:

\begin{equation}
\fbox{$\displaystyle
\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \hspace{.5cm}
\frac{\partial v}{\partial x} = -\frac{\partial u}{\partial y}
\label{eq-Cauchy-Riemann}
$}
\end{equation} 

\begin{marginfigure}[-6.5cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/Bernhard_Riemann#/media/File:Georg_Friedrich_Bernhard_Riemann.jpeg
  \includegraphics{complex/figures/b_riemann}
  \caption{Bernhard Riemann (1826-1866)}
\end{marginfigure}

These are called the \emph{Cauchy--Riemann conditions}. A complex function that satisfies these conditions is called \emph{analytic} (or holomorphic). Important to note is that for a function to be analytic, it necessarily has to be continuous and should not contain any singularities, otherwise the partial derivatives could be undefined.

\subsectionyoutube{The Cauchy-Riemann conditions are sufficient}{cllOl8A4LR8}

We will now show that the Cauchy--Riemann conditions are not only necessary, they are also sufficient (assuming all partial derivatives are continuous).

We can write the total differential

\begin{equation}
d f = \frac{\partial f}{\partial x} d x + \frac{\partial f}{\partial y} d y  = \left( \frac{\partial u}{\partial x}+j\frac{\partial v}{\partial x}\right) d x+\left(\frac{\partial u}{\partial y}+j\frac{\partial v}{\partial y}\right) d y
\end{equation} 

such that

\begin{equation}
\frac{d f}{d z} = \frac{\left(\frac{\partial u}{\partial x}+j\frac{\partial v}{\partial x}\right) d x+\left(\frac{\partial u}{\partial y}+j\frac{\partial v}{\partial y}\right) d y}{d x + j d y}
\end{equation} 

or

\begin{equation}
\frac{d f}{d z} = \frac{\left(\frac{\partial u}{\partial x}+j\frac{\partial v}{\partial x}\right) +\left(\frac{\partial u}{\partial y}+j\frac{\partial v}{\partial y}\right) \frac{d y}{d x}}{1 + j \frac{d y}{d x}} \label{eq-cr-suf}
\end{equation} 

\begin{cue}
Where in Eq.~\ref{eq-cr-suf} is the direction of approach encoded? Get rid of that term by applying the Cauchy-Riemann conditions.
\end{cue}

We now need to prove that this expression is independent on $d y / d x$ in order for the complex derivatives to be independent of the direction of approach. Indeed, each direction of approach will have its own value of $d y / d x$ (e.g. a diagonal approach under 45 degrees will have a value of 1).

Applying the Cauchy--Riemann conditions to the $y$--derivatives, we obtain

\begin{equation}
\frac{\partial u}{\partial y}+j\frac{\partial v}{\partial y} = -\frac{\partial v}{\partial x}+j\frac{\partial u}{\partial x} = j \left( \frac{\partial u}{\partial x}+j\frac{\partial v}{\partial x} \right)
\end{equation}

Substituting this into Eq.\ref{eq-cr-suf}, we get that the factor $1 + j d y / d x$ cancels out, so we lose the  $d y / d x$ dependence:

\begin{equation}
\fbox{$\displaystyle
\frac{d f}{d z} = \frac{\partial u}{\partial x}+j\frac{\partial v}{\partial x}
$}
\end{equation} 

This equation also shows that only derivatives with respect to $x$ are needed to calculate the complex derivative.


\begin{exer}
% difficulty: trivial
% ugent
% youtube: l81NZVwQmW0
Are the following functions analytic? If so, calculate their derivative.
$$\begin{array}{lcll}a) & f(z)=z^2 \\b) & f(z)=z z^* \\c) & f(z)= \Re(z)=x \end{array}$$

What rule-of-thumb can you derive from these results?

\begin{sol}
Analytical and $f'(z)=2z$ / non-analytical / non-analytical. Real-valued functions where you replace $x$ by $z$ are typically analytical. Functions where you make explicit reference to the real and imaginary components of a complex number or to its complex conjugate are not.
\end{sol}
  
\end{exer}

\begin{exer}
  % difficulty: trivial
  % youtube: 8wbS4_Ztd3A
\label{ex-harmonic}
$u$ and $v$ are the real and imaginary parts, respectively, of an analytic function $f(z)$. Show that $u$ and $v$ are \emph{harmonic} functions, i.e. they satisfy Laplace's equation
$$\nabla^2 u = \nabla^2 v = 0$$
\end{exer}

\begin{exer}
  % difficulty: trivial
  % youtube: MZS3Z9o_Bs0
$u$ and $v$ are the real and imaginary parts, respectively, of an analytic function $f(z)$. Show that $|f'(z)|^2$ is equal to the Jacobian determinant
$$\frac{\partial (u,v)}{\partial (x,y)} =  \begin{vmatrix} \partial u / \partial x & \partial u / \partial y \\ \partial v / \partial x & \partial v / \partial y \end{vmatrix}$$
\end{exer}


\pagebreak


\sectionyoutubeugent{Integrals of complex functions}{M-ea1ejVlPE}

With differentiation under control, it is time to study integrals of complex functions. Before we do so however, let's review the definition of a line integral of a real-valued scalar field $f(\mathbf{r})$, which I'm sure you recall from your courses on vector calculus:

\begin{equation}
  \int_{C} f(\mathbf{r})ds \stackrel{def}{=} \int_a^b f\left(\mathbf{r}(t)\right) \|  \mathbf{r}'(t) \| dt
  \label{eq-def-line-integral-scalar}
\end{equation}

Here, the integration path $C$ is parametrised by a variable $t$, resulting in a mapping from $t$ to a vector $\mathbf{r}(t)$ which traces out the curve. The mapping is such that $\mathbf{r}(a)$ is its starting point and $\mathbf{r}(b)$ its end.

Using this as inspiration, it makes sense to define the integral of a complex function along a specified path (see Fig.~\ref{fig-integral}) as follows:

\begin{marginfigure}[-4.5cm]
\centering
\includegraphics{complex/figures/integral}
\caption{A complex line integral.}
\label{fig-integral}
\end{marginfigure}

\begin{equation}
  \int_{C}f(z)dz \stackrel{def}{=} \int_a^b f\left(z(t)\right) z'(t) dt
  \label{eq-def-complex-integral}
\end{equation}
  
\noindent\marginnote{Since $f\left(z\right)$ in Eq.~\ref{eq-def-complex-integral} is intrinsically complex-valued, we also leave $z'(t)$ complex-valued, without bothering to take the norm. In Eq.~\ref{eq-def-line-integral-scalar} however, we had to take the norm to end up with a real-valued result.}Again, the path ${C}$ is parametrised by a mapping from $t$ to a complex number $z(t)$, such that $z(a)=z_0$ and $z(b)=z_1$. In equation \ref{eq-def-complex-integral}, note that $z'(t)$ is shorthand for $\frac{dz(t)}{dt}$ and that $z'(t) dt$ is obviously the chain rule applied to $dz(t)$.

As an example, let's calculate the contour integral $\oint_{C}z^ndz$ where the contour ${C}$ is a counterclockwise circular path of radius $r$ around the origin $z=0$. (The added little circle in the integral symbol is there to denote that we integrate over a closed contour rather than a general path.)

\begin{cue}
Parametrise the curve in polar coordinates using $z=r\exp(j\theta)$ for $\theta=0\to 2 \pi$ and calculate the integral. 
\end{cue}

Expressing the unit cirle as $z=r\exp(j\theta)$ for $\theta=0\to 2 \pi$, we get

$$\oint_{C} z^n dz = \int_0^{2\pi} \left(r^n e^{jn\theta}\right) \left(jr e^{j \theta}d \theta\right)=j r^{n+1} \int_0^{2\pi} e^{j(n+1)\theta} d \theta $$

For $n \neq -1$ this is equal to

$$ \frac{r^{n+1}}{n+1}\left[e^{j(n+1)\theta}\right]_0^{2\pi}=0 $$

because of the periodicity of the exponential. For $n=-1$, we obtain 

$$ \oint_{C} \frac{dz}{z} = j \int_0^{2\pi} d \theta = 2 \pi j $$

which is independent of $r$.

Note that the results of this seemingly trivial integral will prove to have deep consequences later.

\begin{exer}
  % difficulty: trivial
  % youtube: i7F2OP3yENM
Revisit the calculation of  $\oint_{C}z^ndz$, but this time use the parametrisation  $z=r\exp(j\theta^2)$. 
\end{exer}


\pagebreak


\sectionyoutubeugent{Cauchy's integral theorem}{VBvuQbkvG7I}

\begin{marginfigure}[+0.3cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy
  \includegraphics{complex/figures/cauchy}
  \caption{Augustin-Louis Cauchy (1789-1857)}
\end{marginfigure}

One of the major theorems in complex calculus is Cauchy's integral theorem. It states that 

\begin{equation}
\fbox{$\displaystyle
\oint_{{C}} f(z) dz = 0 \label{eq-cauchy-1}
$}
\end{equation}

Important to note is that Eq.~\ref{eq-cauchy-1} only holds if $f(z)$ is analytic for all the points enclosed by the contour ${C}$, as well as for the points on the contour itself.

\begin{cue}
To prove Eq.~\ref{eq-cauchy-1}, first apply the definition of a complex integral given in Eq.~\ref{eq-def-complex-integral}. Then, split up $f$ and $z$ into their real and imaginary components to explicitly calculate the real and imaginary component of the integral.
\end{cue}

Let's start from our definition:

\begin{equation}
  \int_{C}f(z)dz \stackrel{def}{=} \int_a^b f\left(z(t)\right) z'(t) dt
\end{equation}

If we explicitly split up $f$ as $u+jv$ and $z$ as $x+jy$, we get

\begin{equation}
\int_a^b\left[u\left(x(t),y(t)\right)+jv\left(x(t),y(t)\right)\right] \left[x'(t)+jy'(t)\right] dt 
\end{equation}

Let's lighten our notational load by omitting the arguments of the various functions, and by writing $x'(t)dt=dx$ and $y'(t)dt=dy$. Also, if we explicitly separate out the real and the imaginary parts, we obtain:

\begin{align}
\oint_{C}f(z)dz = & \int_a^b\left(u+jv\right)(dx+jdy)
\nonumber \\
  = & \int_a^b\left[udx-vdy\right] + \nonumber \\
  & j \int_a^b\left[vdx+udy\right] \label{eq-cauchy-proof}
\end{align}

Again, remember what's behind this shorthand: $dx$ and $dy$ are not independent, but they both depend on $t$, encoding the shape of the contour.

Eq.~\ref{eq-cauchy-proof} also gives us another way of intepreting the real and the imaginary part of a complex integral, as (hopefully well-known) real-valued line integrals of vector fields. Let's recall the definition of such integrals:

\begin{equation}
  \int_{C} \mathbf{A}(\mathbf{r})\cdot d\mathbf{r} \stackrel{def}{=} \int_a^b \mathbf{A}\left(\mathbf{r}(t)\right) \cdot  \mathbf{r}'(t) dt
  \label{eq-def-line-integral-vector}
\end{equation}

Another way of writing this is $\int_{C} A_xdx + A_ydy + A_zdz$, which shows the similarity with Eq.~\ref{eq-cauchy-proof}.


\begin{marginfigure}[-0.0cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/Sir_George_Stokes,_1st_Baronet#/media/File:Ggstokes.jpg
  \includegraphics{complex/figures/stokes}
  \caption{George Stokes (1819-1903)}
\end{marginfigure}

Back to our proof. In order to be able to use the Cauchy-Riemann conditions, we somehow need to bring partial derivatives into this formula. For this, we will use Stokes's theorem:

\begin{equation}
\oint_{{{C}}} {\mathbf A}(\mathbf{r}) \cdot d {\mathbf r} = \iint_S \nabla \times {\mathbf A}(\mathbf{r}) \cdot d {\mathbf S}
\end{equation}

\begin{cue}
Convert Stokes's theorem to our two-dimensional case.
\end{cue}

In two dimensions (i.e. $A_z=0$ and the contour contained in the $(x,y)$--plane), Stokes becomes:

\begin{equation}
\oint_{{C}} \left(A_x dx + A_y dy\right) = \iint_S \left(\frac{\partial
A_y}{\partial x} - \frac{\partial A_x}{\partial y} \right)dx dy
\end{equation} 

\begin{cue}
Figure out which values of $A_x$ and $A_y$ to use, so that we can apply Cauchy--Riemann to the first term in Eq.~\ref{eq-cauchy-proof}.
\end{cue}

For the first term in Eq.~\ref{eq-cauchy-proof}, we choose $A_x=u$ and $A_y=-v$ such that

\begin{align}
\oint_{C}\left[u(x,y)dx-v(x,y)dy\right] =& \oint_{{C}} \left(A_x dx + A_y dy\right) \nonumber \\
=& \iint_S \left(\frac{\partial A_y}{\partial x} - \frac{\partial A_x}{\partial y} \right)dx dy \nonumber \\ =& -\iint_S \left(\frac{\partial v}{\partial x} + \frac{\partial u}{\partial y} \right)dx dy 
\end{align} 

Because of the Cauchy--Riemann conditions Eq.~\ref{eq-Cauchy-Riemann}, this
vanishes.

\begin{cue}
Which values of $A_x$ and $A_y$ should we use for the second term in Eq.~\ref{eq-cauchy-proof}?
\end{cue}

A similar conclusion can be drawn for the second term in Eq.~\ref{eq-cauchy-proof} by setting $A_x=v$ and $A_y=u$, which proves that the entire integral in Eq.~\ref{eq-cauchy-1} vanishes.

\begin{exer}
  % difficulty: trivial
  % youtube: _u3lqk3sxyQ
Prove that for an analytic function $f(z)$ the line integral 
$$\int_{z_0}^{z_1}f(z)dz$$
is independent on the exact path between $z_0$ and $z_1$.
\end{exer}


\pagebreak

\sectionyoutubeugent{Cauchy's integral formula}{UK-bUjR-v_U}
\label{week1}

The second major theorem in complex calculus is Cauchy's integral \emph{formula} (as opposed to Cauchy's integral \emph{theorem} from the previous section). Cauchy integral formula states that for an analytic function $f(z)$

\begin{equation}
\fbox{$\displaystyle
\frac{1}{2 \pi j}\oint_{{C}} \frac{f(z)} {z-z_0} dz = f(z_0)
\label{eq-cauchy-2}
$}
\end{equation}

Important here is that $z_0$ is a point enclosed by the contour ${C}$.

\begin{cue}
What would happen to Eq.~\ref{eq-cauchy-2} if  $z_0$ were outside of the contour?  
\end{cue}

If $z_0$ were outside of the contour, then the integrand of Eq.~\ref{eq-cauchy-2} would be analytic in the entire region enclosed by the contour. In that case, Cauchy's theorem applies and the integral vanishes.

\begin{marginfigure}[-1cm]
\centering
\includegraphics[width=5cm]{complex/figures/cauchy_II}
\caption{Contour to prove Cauchy's formula. (The arrow near the path $C_2$ refers to the direction in which it is taken to be positive, not to the direction in which it is traversed as part of the bigger contour $C$.)}
\label{fig-cauchy-II}
\end{marginfigure}

To prove Eq.~\ref{eq-cauchy-2}, we note that although the function $f(z)$ is analytic, $f(z)/(z-z_0)$ is not, because is has a singularity at $z=z_0$. However, if we deform ${C}$ to exclude the singularity as in Fig.~\ref{fig-cauchy-II}, we end up with an extended contour where Cauchy's theorem does apply. Our ultimate goal is to bring the two straight sections of this contour infinitely close together, so that our original contour $C$ becomes fully contained in the extended contour.

\begin{cue}
Apply Cauchy's theorem to this extended contour, and split up the contributions from its different parts. Bring the two straight lines infinitely close together. What happens to their contributions?
\end{cue}

The result is

\begin{equation}
\oint_{{C}} \frac{f(z)} {z-z_0} dz -\oint_{{C}_2} \frac{f(z)}
{z-z_0} dz=0
\end{equation} 

\noindent\marginnote{By convention, contours are positive when traversed in the counterclockwise direction.}Here, ${C}$ is the original outer contour and ${C}_2$ is the circle surrounding the point $z_0$ traversed in a counterclockwise direction (hence the minus sign, because in the extended contour we should traverse it in the clockwise direction). In the limit of becoming infinitely close together, the two straight sections cancel because $f(z)$ is continuous (a side effect of it being analytic).

\begin{cue}
Parametrise ${C}_2$ and calculate its contribution to the integral. Then, take the limit $ r \to 0 $ to prove Cauchy's formula.   
\end{cue}

To calculate the integral along ${C}_2$, we use the parametrisation $z=z_0 + r e^{j\theta}$:

\begin{equation}
\oint_{{C}_2} \frac{f(z)} {z-z_0} dz = \int_0^{2\pi} \frac{f(z_0
+ r e^{j\theta})} {r e^{j\theta}} \left(rje^{j \theta} d \theta\right)
\end{equation}

\noindent\marginnote{We're assuming our functions are sufficiently well-behaved so that we can exchange the order of limit and integration.}In the limit $ r \to 0 $, the integrand becomes a constant so that we can write:

\begin{align}
\oint_{{C}_2} \frac{f(z)} {z-z_0} dz = & \, j f(z_0)  \int_0^{2\pi} d \theta \nonumber \\
 = & \, 2 \pi j f(z_0)
\end{align}
 
which proves Cauchy's integral formula.

Note that this formula is quite remarkable. It means that as soon as the values of an analytic function are specified on a contour, we immediately know the function values at all the interior points!


\begin{exer}
% difficulty: trivial
% ugent
% youtube: F8DqIP6fnpw
Use Cauchy's formula to calculate 
$$\oint_{{C}}  \frac {e^z} {z+1} dz$$
Here ${C}$ is a circle of radius 4 centered at the origin.
\begin{sol}
$$\frac{2 \pi j}{e}$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: G4Fm4Vgk0VU
Use Cauchy's formula to calculate 
$$\oint_{{C}}  \frac {e^{az}} {z} dz$$
Here ${C}$ is the unit circle and $a$ is a real-valued constant. Then, write this integral in terms of $\theta$ and show
$$ \int_0^\pi e ^{a \cos \theta} \cos (a \sin \theta) d\theta = \pi $$
\begin{sol}
$$2 \pi j$$
\end{sol}
\end{exer}

\begin{exer}
% difficulty: hard
% ugent
% youtube: YtdU-XXWwnk
\label{ex-cauchy-diff}
Prove the following identity:

$$f'(z_0)=\frac{1}{2 \pi j} \oint_{{C}} \frac{f(z)} {(z-z_0)^2} dz$$

This expression can be used to (numerically) calculate the derivative of an analytic function.
\begin{hnt}
Apply Cauchy's formula to each of the terms of $$\frac{f(z_0+\Delta z_0) - f(z_0)}{\Delta z_0}$$ Then take the limit ${\Delta z_0} \to 0$.
\end{hnt}
\end{exer}

\begin{exer}
  % difficulty: hard
  % youtube: tyNs5agWKZw
Show that

  $$f^{(n)}(z_0)=\frac{n!}{2 \pi j} \oint_{{C}} \frac{f(z)} {(z-z_0)^{n+1}} dz$$
  
This also means that if a function is analytic, then the derivatives of any order automatically exist.
\begin{hnt}
Use induction and repeat the technique used in Ex. \ref{ex-cauchy-diff}.
\end{hnt}  
\end{exer}


\pagebreak


\sectionugent{Laurent series}

\subsectionyoutube{An extension for Taylor series}{dAH_GZN74Qc}

Let's use what we have learned so far to try and come up with a series expansion of complex functions around a certain point $z_o$. What's more, we want to move beyond replacing $x$ by $z$ in a Taylor series, and also allow for the case where the function is not holomorphic around $z_o$. Consider e.g. a function that is analytic in some annular region around the origin of inner radius $r$ and outer radius $R$.

\begin{cue}
Would a circular contour work in this situation, if we want to apply Cauchy's formula?
\end{cue}

\begin{marginfigure}
\includegraphics{complex/figures/laurent}
\caption{Contour to derive Laurent series. (The arrows refer to the direction in which $C_1$ and $C_2$ are taken to be positive.)}
\label{fig-laurent}
\end{marginfigure}

A simple circular contour would enclose the inner region where the function is not analytic, so we need to construct a more complicated contour that only encloses points where the function is analytic (Fig.~\ref{fig-laurent}). For ease of notation, we'll take the point $z_0$ to be the origin from now on.

\begin{cue}
Apply Cauchy's formula, and split up the contour into its different parts. Bring the straight segments infinitely close together.
\end{cue}

Cauchy's formula gives us

\begin{equation}
f(z)=\frac{1}{2 \pi j }\oint_{{C}_1} \frac{f(z')} {z'-z} dz' -\frac{1}{2
\pi j }\oint_{{C}_2} \frac{f(z')} {z'-z} dz' \label{laurent_0}
\end{equation} 

Here, $z$ is a fixed point on the inside of the contour, while $z'$ is the integration variable running along the contour. Just like in the previous section, the two line segments cancel.

Our aim is to transform this formula into a series expansion. One can prove that the following straightforward generalisation of the well--known geometric series expansion holds:

\begin{equation}
\frac{1}{1-z} = \sum_{n=0}^\infty z^n, \hspace{.5cm} |z| < 1
\end{equation}

\begin{cue}
Manipulate the different terms in Eq.~\ref{laurent_0} so that we are able to use the geometric series. Pay special attention to the radius of convergence, by dividing the numerator and denominator by $z$ or $z'$.
\end{cue}

Simple manipulation of Eq.~\ref{laurent_0} yields

\begin{equation}
f(z)=\frac{1}{2 \pi j }\oint_{{C}_1} f(z') \frac{1 / z'} {1-z / z'} dz' + \frac{1}{2 \pi j }\oint_{{C}_2} f(z') \frac{1 / z} {1 - z' / z} dz'
\label{eq-laurent-1}
\end{equation} 

Note that $z$ is on the inside of ${C}_1$, such that $| z | < |z'| $, or $ |z / z' | < 1$ in the first term in Eq.~\ref{eq-laurent-1}. Similarly, $z$ is on the outside of ${C}_2$, such that $|z'| < | z | $, or $ |z'  / z| <
1$ in the second term in Eq.~\ref{eq-laurent-1}.

With this, we can write Eq.~\ref{eq-laurent-1} as

\begin{equation}
f(z)=\frac{1}{2 \pi j }\oint_{{C}_1} \frac{f(z')}{z'} \sum_{m=0}^{\infty} \left( \frac{z}{z'}\right)^m dz' + \frac{1}{2 \pi j }\oint_{{C}_2} \frac{f(z')}{z} \sum_{n=0}^{\infty} \left(\frac{z'}{z}\right)^n dz'
\end{equation}

\begin{cue}
Clean up this formula so that the coefficients of the power series become clearly visible.
\end{cue}

Note that as far as the integration over $z'$ is concerned, $z$ is just a constant. So, provided our functions are sufficiently well-behaved to exchange summation and integration, we can write

\begin{equation}
f(z)=\frac{1}{2 \pi j } \sum_{m=0}^{\infty} z^m \oint_{{C}_1} \frac{f(z')}{z^{\prime (m+1)}} dz' + \frac{1}{2 \pi j } \sum_{n=0}^{\infty} z ^ {-n-1} \oint_{{C}_2}  {f(z')}  (z')^ n dz'
\end{equation} 

or more symmetrically

\begin{equation}
f(z)=\frac{1}{2 \pi j } \sum_{m=0}^{\infty} z^m \oint_{{C}_1} \frac{f(z')}{z^{\prime (m+1)}} dz' + \frac{1}{2 \pi j } \sum_{n=1}^{\infty} z ^ {-n} \oint_{{C}_2} \frac{f(z')}{z^{\prime^ {(-n+1)}}} dz'
\label{eq-laurent-int}
\end{equation} 

The contour integrals are just numbers in the end, so this means that around the origin, we can expand $f(z)$ in a power series containing both negative and positive powers of $z$:

\begin{equation}
f(z)= \sum_{m=-\infty}^{\infty} a_m z^m
\end{equation} 

\begin{marginfigure}[-5.5cm]
  % credits: Wikipedia
  % url: https://upload.wikimedia.org/wikipedia/commons/d/d8/Pierre_Alphonse_Laurent.jpeg
  \includegraphics{complex/figures/pierre_laurent}
  \caption{Pierre Alphonse Laurent (1813–1854)}
\end{marginfigure}

It's the negative powers of $z$ that deal with the singular part of $f(z)$. This generalisation of a Taylor series in the presence of singularities is called a \emph{Laurent series}, in this case a Laurent series around the origin.

\subsectionyoutube{An example of a Laurent series}{dvv1XAgzBcI}

As an example, let's develop

$$f(z)=\frac{1}{z(z-1)}$$

in a Laurent series around the origin for the two rings $0 < | z | < 1$ and $ 1 < |z|$.

\begin{cue}
Do this first for the region where  $| z | < 1$, using the geometric series.
\end{cue}

For the first ring where $| z | < 1$, we can easily write

$$f(z)=\frac{1}{z} \cdot \frac{1}{z-1} = -\frac{1}{z} \sum_{m=0}^{\infty} z^m =-\frac{1}{z}-1-z-z^2 \cdots$$

The presence of $-\frac{1}{z}$ is a clear fingerprint of the singularity at the origin.

In the second ring  $ 1 < |z|$, this series does not converge, so we need to do something else.

\begin{cue}
Divide the numerator and denominator of the final factor of $f(z)$ by $z$, such that you can use the geometric series again.
\end{cue}

We can write

$$f(z)=\frac{1}{z} \cdot \frac{1 / z }{1-1/z} = \frac{1}{z^2} \sum_{m=0}^{\infty} \frac{1}{z^m} =\cdots+\frac{1}{z^4}+\frac{1}{z^3} + \frac{1}{z^2}$$

This series converges in the second ring, since $|1/z| < 1$ there.

\pagebreak

\begin{exer}
% difficulty: normal
% ugent
% youtube: 59Xeatg1Css
\label{ex_laurent_1}
Develop

$$f(z)=\frac{e^z}{z-1}$$

in a Laurent series around the origin for the ring $0 < | z | < 1$.

$e^z$ is a function which is analytic in all of $\mathbb{C}$ and defined by

$$e^z \stackrel{def}{=} \sum_{m=0}^{\infty} \frac{z^m}{m!} $$

Can you also think of a graphical representation that helps you take the product of the two series expansions? (It's helpful to look at the solution video here.)

\begin{sol}
$$f(z)= - \sum_{k=0}^{\infty} \left(\sum _{m=0}^k \frac{1}{m!} \right) z^k $$
\end{sol}

\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: Jo_c_zza3aA
  Same as Exercise \ref{ex_laurent_1}, but for the outer ring  $1 < | z |$.

\begin{sol}
$$f(z)=  \sum_{k=-\infty}^{\infty} \left(\sum_{m=k+1}^\infty \frac{1}{m!} \right) z^k $$
\end{sol}
  
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: KRT-6y-UJjQ
  Show that you can change the radii of the contours used to derive the Laurent series, as long as they stay in the holomorphic region and keep their relative position with respect to $z$.

\end{exer}

\begin{exer}
  % difficulty: hard
  % youtube: _O9GqRJrZuM
What is the relationship between a Fourier and a Laurent series?
  \begin{hnt}
  Transform a Fourier series in exponential notation to a Laurent series.
  \end{hnt}
\end{exer}


\pagebreak


\sectionugent{Singularities}

In essence, $z_0$ is a singular point of $f(z)$, if $f(z)$ is not analytic there. There are two important types of singularities. The first type is the more pedestrian of the two, and consists of so-called \emph{poles}. The second type originates from measures to combat multivaluedness in functions like square roots, which gives rise to singularities called \emph{branch points} and \emph{branch cuts}. 

We will now discuss these concepts in more detail.

\subsectionyoutube{Poles}{hxLwJcCERoI}

Let's develop $f(z)$ in a Laurent series around $z_0$:

\begin{equation}
f(z)= \sum_{m=-\infty}^{\infty} a_m (z-z_0)^m
\end{equation} 

Obviously, the function will only blow up if you have negative powers of $z-z_0$. In that case, suppose the index $m$ doesn't run all the way to $-\infty$, but only to a finite negative value $-M$, $z_0$ is called a \emph{pole of order $M$}. As a trivial example, $f(z)=1/z$ has a pole of order 1 at $z=0$ (also called a \emph{simple pole}). $f(z)=1/z^2$ has a pole of order 2 at $z=0$.

On the other hand, if there is an infinite number of negative $m$--values for which $a_m$ is non--zero, $z_0$ is called an \emph{essential singularity}. You could say this is like a pole of infinite order.

\begin{cue}
  Verify by looking at the series expansion that $f(z)=e^{1/z}$ has an essential singularity.  
\end{cue}

Since

$$e^{1/z} = \sum_{m=0}^{\infty} \frac{1}{z^m m!} $$

has an infinite number of negative powers of $z$, it is an essential singularity.

Say you have a function $f(z)$ that has a pole of order $M$. You can create a new function that does not have this pole by multiplying $f(z)$ by $(z-z_0)^M$. This obviously cannot be done for an essential singularity, as multiplying by something like $(z-z_0)^\infty$ does not make a lot of sense.

\noindent\marginnote{This is shown in Picard's Great Theorem.}One can also prove that in a small neighbourhood around an essential singularity, the function actually takes all possible complex values (with at most a single exception)! So, obviously it makes no sense to talk about the limit of that function there.

\subsectionyoutube{The complex square root and Riemann surfaces}{Os59TyXEb30}

We're very familiar with real-valued square roots. For a positive value of $x$, we can say that $y = \sqrt{x}$ is what we get when we solve the equation $x=y^2$ for $y$. However, we often forget that there's actually two solutions to that equation, namely $y = \sqrt{x}$ and $y = -\sqrt{x}$.

\noindent\marginnote[1.5cm]{As a notational oddity, the complex square root is designated by the power $1/2$, to distinguish it from the real-valued square root.}How does that story play out in the complex domain? Let's solve $z=w^2$ for $w$ to give us

\begin{equation}
w = f(z) = z^{1/2} \label{eq-sqrt}
\end{equation}

\begin{cue}
For a given value of $z$, how many solutions $w$ does the complex square root have? 
\end{cue}

For $z=\rho e^{j\theta}$, a possible solution to Eq.~\ref{eq-sqrt} is $w_1 = \sqrt{\rho} e^{j\theta/2}$. However, there is a different point in the $w$--plane that corresponds to the same $z$, namely  $w_2=-w_1$. 

Another way of getting to this second solution is by realising that the phase in the $z$-plane is only defined up to a multiple of $2\pi$, so we can actually write that  $z=\rho e^{j(\theta +2\pi)}$. Taking the real-valued square root of the modulus and halving the argument brings us then to $w_2 = \sqrt{\rho} e^{j(\theta/2+\pi)} = -w_1$.

So, Eq.~\ref{eq-sqrt} is clearly not a single--valued function: a single point in the $z$--plane (except $z=0$) corresponds to two points in the $w$--plane. To get a handle on the multivaluedness of $z^{1/2}$, it's instructive to look at a graphical representation of this complex function. Since this is essentially a 4D--object, we can plot e.g. a 3D projection $(\Re(z),\Im(z),\Re(w))$ and use the phase of $w$ to colour the surface. This is done in Fig.~\ref{fig-riemann}.

\begin{marginfigure}[-3cm]
\centering
\includegraphics{complex/figures/riemann}
\caption{Riemann surface of $w=z^{1/2}$. Note that $u=\Re(w)$. }
\label{fig-riemann}
\end{marginfigure}

Fig.~\ref{fig-riemann} is a so-called \emph{Riemann surface} associated with complex square root. You can see that the parabola representing the real-valued square root is also embedded in this surface. Additionally, the Riemann surface clearly shows the multivaluedness of the square root: for each point in the $z$--plane there are two points on the surface, one in the top part and one in the bottom part. 

Another way to appreciate this multivaluedness, is picking a point on the Riemann surface, and making a full round trip on that surface to arrive back at our starting location.

\begin{cue}
When you do such an excursion in the complex plane, how does the argument of the point travelling on the Riemann surface change? 
\end{cue}

From the figure, it is clear that we will have circled twice around the origin for that path, so one could say that on the Riemann surface, the argument needs to change over $4 \pi$ in order to complete a full round trip. Therefore, this  surface can be seen as an extension of the complex plane which is 'twice as large' as the regular complex plane.

\pagebreak

\subsectionyoutube{Branch points and branch cuts}{Lh6rHAiY9KE}

Although the Riemann surface is a very profound and beautiful mathematical concept, for practical purposes people often like to work with single--valued functions mapping the complex plane to the regular (i.e. non-extended) complex plane. To do this, we can adopt a convention to restrict ourselves e.g. to outputs in the right half of the $w$--plane, i.e. where $\Re(w)>0$.


\begin{marginfigure}[-1cm]
\centering
\includegraphics[width=4cm]{complex/figures/branchcut_portrait}
\caption{The mapping $w=z^{1/2}$.}
\label{fig-branchcut}
\end{marginfigure}


\begin{cue}
To which figure in the $z$--plane does the boundary $\Re(w)=0$ map?
\end{cue}

On the boundary $\Re(w)=0$, we have $w=\pm jv$. Given that $z=w^2$, the boundary between these two halves of the $w$--plane corresponds to the negative real axis in the $z$--plane. We call this negative real $z$--axis a \emph{branch cut}, originating from the \emph{branch point} $z=0$ (see Fig.~\ref{fig-branchcut}).

\begin{cue}
Looking at Fig.~\ref{fig-branchcut}, once we introduce the branch cut, what is the square root of $z_+$ and $z_-$? What happens to the output of the function if you cross the branch cut in the $z$--plane? 
\end{cue}

For $z_+$ just above the branch cut, we can write a polar form $z_+ = \rho e^{j (\pi - \epsilon)}$, with $\epsilon$ a small angle that will tend to zero. Calculating the square root, we get $w_+ = \sqrt{\rho} e^{j (\pi/2 - \epsilon/2)}$, which lies indeed in the right half plane (see Fig.~\ref{fig-branchcut}).

On the other hand, for $z_- = \rho e^{j (\pi + \epsilon)}$, naively calculation the square root, we get $w_- = \sqrt{\rho} e^{j (\pi/2 + \epsilon/2)}$, which is lying in the wrong half plane. So, actually $w_- = \sqrt{\rho} e^{j (\pi/2 + \epsilon/2)} e^{j \pi}$.  

In the limit of zero $\epsilon$, $w_+$ tends to $j\sqrt{\rho}$, whereas $w_-$ tends to $-j\sqrt{\rho}$. This clearly shows that our function is no longer continuous when crossing the branch cut.

The relationship between branch cuts and the Riemann surface is shown schematically in Fig.~\ref{fig-sheets}: our branch cut cuts the Riemann surface in two separate \emph{Riemann sheets}. In the first sheet, the argument of $z$ moves from $-\pi$ at B to $\pi$ at A. In the second sheet, we could say by convention that the argument actually is in the extended interval $[\pi, 3\pi]$.

\begin{marginfigure}[-2cm]
\centering
\includegraphics{complex/figures/sheets}
\caption{The branch cut cuts the Riemann surface in two separate Riemann sheets.
Adjacent regions on the Riemann surface are marked by the same letters.}
\label{fig-sheets}
\end{marginfigure}
It is important to remark that, when choosing a contour to evaluate the integral theorems we've seen so far, we are not allowed to cross a branch cut, as the resulting discontinuity would make the function no longer analytic. However, skirting on one edge of a branch cut, circling around the branch point and returning along the other edge is allowed, as the function stays continuous and analytic throughout the entire path. 

Note that integrals on both sides of a branch cut will generally not cancel out, unlike integrals on both sides of the contour cut in Fig.~\ref{fig-cauchy-II}, which only serves to transform a contour into one which can be used to apply Cauchy's theorem.

\noindent\marginnote[]{When you calculate $k_z=\pm (k^2-k_x^2)^{1/2}$, you might want to pick a certain sign for the square root to ensure e.g. damped our outgoing waves.}The choice of branch cut is in no way unique: any line (even a curved one) from $z=0$ to infinity would suit the purpose equally well. Its only goal is to lift the ambiguity with respect to the choice of $w$, and ensuring that the function is continuous outside of the branch cut. There are however often physical reasons which inspire the choice of branch cut.

\begin{exer}
% difficulty: normal
% ugent
% youtube: 6ecPpRUTieg
\label{ex-branch-ang}
Show that asking that $\Re(w)>0$ is equivalent to asking that you restrict the angle of $z$ to $[-\pi, \pi]$ before halving it to calculate the square root. Do this by looking at 4 strategically located points in the $z$-plane (just above/below the positive/negative real axis). Write down their angles, and then see what the corresponding angles in the $w$--plane are. Are the results in the correct half plane? Verify that crossing the branch cut leads to a discontinuity. (It's helpful to look at the solution video here.)
\end{exer}

\begin{exer}
% difficulty: normal
% ugent
% youtube: y-F1acXHgAk
\label{ex-product-roots}
\begin{marginfigure}[0.5cm]
\centering
\includegraphics[width=4cm]{complex/figures/riemann2}
\caption{Half the Riemann surface of $w=(z-1)^{1/2}(z+1)^{1/2}$. Note that $u=\Re(w)$. }
\label{fig-riemann2}
\end{marginfigure}
Consider

$$f(z)=(z-1)^{1/2}(z+1)^{1/2}$$

Using the conventional choice of branch cut for an individual square root (expressed in terms of angles as in Ex.~\ref{ex-branch-ang}), show that the branch cut for this product of square roots is the segment $-1 \le x \le 1$. Do this by looking at 8 strategically located points in the $z$--plane, and calculate the angle of the corresponding $w$--value.


Verify that it is possible to establish a single--valued function using this cut, and that any contour which does not cross this cut does not encounter discontinuities.
\end{exer}

\pagebreak

\begin{exer}
  % difficulty: normal
  % youtube: 2jV5xidyl2o
How many sheets does the Riemann surface of $w=\ln(z)$ have?
\end{exer}

\begin{exer}
  % difficulty: hard
  % youtube: siBBZMkJrB8
\begin{marginfigure}[0.cm]
\centering
\includegraphics[width=4cm]{complex/figures/riemann3}
\caption{Half the Riemann surface of $w=(z-1)^{1/2}(z+1)^{1/2}$. Note that $v=\Im(w)$. }
\label{fig-riemann3}
\end{marginfigure}

For Ex.~\ref{ex-product-roots}, what range of angles would you need to chose for the arguments of each of the square roots in order to end up with a branch cut consisting of the union of  $x \le -1$ and $1 \le x$?


Note that Fig.~\ref{fig-riemann2} and \ref{fig-riemann3} each seem to suggest a different natural choice for a branchut, even though they both correspond to the same Riemann surface.


Why is that? Which branch cut is more natural?
  \begin{sol}
    $\arg(z-1) \in [0, 2 \pi], \arg(z+1) \in [-\pi,\pi]$. Figs.~\ref{fig-riemann2} and \ref{fig-riemann3} are both different projections of a 4D Riemann surface. That they seem to suggest a certain natural choice for the branchcut is purely accidental.
\end{sol}
\end{exer}

\pagebreak


\sectionugent{Residue calculus}

One of the main goals of this chapter is to provide you with a powerful way of calculating some real-valued integrals by transforming them to complex contour integrals, and solve them using straightforward algebra, as opposed to using tricky calculus. An important ingredient in this recipe is the use of so-called \emph{residue calculus}.

\subsectionyoutube{Definition of the residue}{FLENulJ6dFg}

Suppose $z_0$ is an isolated singularity of $f(z)$. We can develop this function in a Laurent series around $z_0$:

\begin{equation}
f(z)= \sum_{m=-\infty}^{\infty} a_m (z-z_0)^m
\end{equation} 

The \emph{residue} of $z_0$ is defined as $a_{-1}$, i.e. the coefficient of $1/z$ in the Laurent series. Using Eq.~\ref{eq-laurent-int}, we immediately get

\begin{equation}
\mathrm{Res}_{z_0}=\frac{1}{2 \pi j }  \oint_{{C}} f(z) dz \label{eq-res-int}
\end{equation}

\begin{cue}
  By looking at their series expansion, calculate the residues of the following functions at $z=0$.
  $$\begin{array}{lcll}a) & f(z)=1/z \\b) & f(z)=1/z^2 \\c) & f(z)=e^{1/z}\end{array}$$
\end{cue}

For $f(z)=1/z$ and $f(z)=1/z^2$, the series expansion is the function itself, so we can quickly see that the residues are 1 and 0 respectively.

$z=0$ is an essential singularity of $f(z)=e^{1/z}$ with residue 1, since

$$e^{1/z} = \sum_{m=0}^{\infty} \frac{1}{z^m m!} $$

\pagebreak 

\begin{exer}
  % difficulty: trivial
  % youtube: 3yTQUc3fZSU
  Integrate the Laurent series around a singularity term-by-term. What formula do you recover?
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: B5Il6eMovPg
  Use a series expansion to calculate the residue at $z=0$ of
  $$z \cos \frac{1}{z}$$
  \begin{sol}
    $$-1/2$$
  \end{sol}
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: IZGlLE09wOQ
  Use a series expansion to calculate the residue at $z=0$ of

  $$\frac{z - \sin z}{z}$$
  \begin{sol}
    $$0$$
  \end{sol}
\end{exer}

\pagebreak

\subsectionyoutube{Residue theorem}{_fw89fpAJIQ}

Suppose $f(z)$ is analytic inside a contour ${C}$, except for some isolated singularities $z_k$ inside ${C}$ (so, branch cuts are not allowed, but e.g. poles are OK). Then

\begin{equation}
\fbox{$\displaystyle
\oint_{{C}} f(z) dz = 2 \pi j \sum_k \mathrm{Res}_{z_k} \label{eq-res-theorem}
$}
\end{equation} 

The summation index $k$ runs over all singularities enclosed by the contour. Note that no singularity should lie on the contour itself.

\begin{marginfigure}
\centering
\includegraphics{complex/figures/residue}
\caption{Contour to prove residue theorem. (The arrows near the singularities refer to the direction in which the path is taken to be positive, not to the direction in which it is traversed as part of the bigger contour $C$.)}
\label{fig-residue}
\end{marginfigure}

To prove Eq.~\ref{eq-res-theorem}, we make use of the contour in Fig.~\ref{fig-residue}.

\begin{cue}
  Apply Cauchy's theorem on this contour. Then, use the relation between the residue and a contour integral around the singularity (Eq.~\ref{eq-res-int}) to prove the residue theorem. 
\end{cue}

Applying Cauchy's theorem on this contour (the straight segments cancel as before):

\begin{equation}
\oint_{{C}} f(z) dz - \sum_k \oint_{{C}_k} f(z) dz = 0
\label{eq-res-proof-1}
\end{equation}

The integral around any singular point can be written as (Eq.~\ref{eq-res-int})

\begin{equation}
\oint_{{C}_k} f(z) dz = 2 \pi j \mathrm{Res}_{z_k} \label{eq-res-proof-2}
\end{equation} 

Combining Eq.~\ref{eq-res-proof-1} and Eq.~\ref{eq-res-proof-2} immediately proves the theorem.

\pagebreak

\subsection*{Calculating residues}

The residue theorem is of enormous practical importance, as it allows us to replace the cumbersome problem of evaluating contour integrals by the algebraic problem of calculating residues at enclosed singular points. Because of its importance, we will now discuss a number of techniques that allow us to easily calculate the residues, apart from writing down the Laurent series, or applying Eq.~\ref{eq-res-int}. The proofs are left as an exercise. The formulas for the case of a single pole are worth memorising.

\begin{exer}
% difficulty: normal
% ugent
% youtube: eeAa-wZ2iDc
  If $z_0$ is a simple pole of $f(z)$, use the Laurent series to prove that
  $$\mathrm{Res}_{z_0} = \left[f(z)(z-z_0)\right]_{z=z_0}$$

  (Explicitly writing down the first few terms of the Laurent series makes this slightly easier to solve.)
  
\label{ex-res1}
\end{exer}

\begin{exer}
  % difficulty: trivial
  % youtube: UUbcQvMs134
  Calculate the residue at $z=0$ of

   $$\frac{1}{z+z^2}$$ 
\begin{sol}
  $$1$$
\end{sol}
\end{exer}

\begin{exer}
% difficulty: hard
% ugent
% youtube: rVRDlqpRcxk
  If $z_0$ is a simple pole of $f(z)=\frac{g(z)}{h(z)}$, i.e. $z_0$ is a simple zero of $h(z)$ and $g(z_0) \ne 0$, show that
    $$\mathrm{Res}_{z_0} = \frac{g(z_0)}{h'(z_0)}$$
\begin{hnt}
Write $h(z)$ as $r(z)(z-z_0)$, and apply the result from Ex.~\ref{ex-res1}.
\end{hnt}
\end{exer}

\begin{exer}
  % difficulty: hard
  % youtube: LQNlwXZKlQo
If $z_0$ is a pole of order $M$ of $f(z)$, prove that
$$\mathrm{Res}_{z_0} = \frac{1}{(M-1)!}{\left[\frac{d^{M-1}}{dz^{M-1}}[f(z)(z-z_0)^M]\right]}_{z=z_0}$$
\end{exer}


\pagebreak


\sectionugent{Limit theorems}
\label{week2}

Sometimes, we are dealing with contours that are infinitely large or infinitely small. For these cases, the following limit theorems (which we will present mostly without proof) are of great practical importance.

\subsectionyoutube{Jordan's lemma}{5DwtmA-jR7I}

\begin{marginfigure}
\centering
\includegraphics[width=4cm]{complex/figures/jordan}
\caption{Jordan's lemma.}
\label{fig-jordan}
\end{marginfigure}

Jordan's lemma deals with integrals along a circular path  (see Fig.~\ref{fig-jordan}) containing a complex exponential: 

$$ \int_{{C}_R} f(z) e^{\beta z} dz$$

Note that here (and also for the next limit theorems) ${{C}_R}$ only includes the circular part of the contour and not the straight line segments.

Under which circumstances does this integral go to zero if the radius $R$ goes to infinity? It seems reasonably that both factors of the integrand should go to zero for that. However, the exponential does not go to zero at infinity everywhere in the complex plane. 

\begin{cue}
Show that if $b>0$, then $e^{jbz}$ goes to zero if $z$ goes to infinity, but only in the upper half plane.
\end{cue}

Given that $e^{jb(x+jy)} \propto e^{-by}}$, this only vanishes for positive $y$, i.e. in the upper half plane. 

It can be shown that in general, for a contour lying on the 'proper' side of $a$, i.e. the half plane not containing $a+\beta^*$ (see Fig.~\ref{fig-jordan}), we have that if

\begin{marginfigure}[-2.5cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/Camille_Jordan
  \includegraphics{complex/figures/camille_jordan}
  \caption{Camille Jordan (1838–1922) }
\end{marginfigure}

\begin{equation}
\lim_{z \to \infty} f(z) = 0
\end{equation}
then
\begin{equation}
\lim_{R \to \infty} \int_{{C}_R} f(z) e^{\beta z} dz = 0
\end{equation}

\begin{cue}
Verify that the construction of the 'proper' half plane reduces to the upper half plane in case $a=0$ for $ \int_{{C}_R} f(z) e^{jb z} dz$ with $b>0$.
\end{cue}

\subsectionyoutube{Big and small limit theorems}{F421niAjGs8}

For a circular contour spanning an angle $\alpha$ with top at $z=a$ (see Fig.~\ref{fig-limit-theorem}), we have that if

\begin{equation}
\lim_{z \to \infty}  f(z) (z-a) = A
\end{equation}
then
\begin{equation}
\lim_{R \to \infty} \int_{{C}_R} f(z) dz = j \alpha A
\end{equation}

\begin{marginfigure}
\centering
\includegraphics[width=3.5cm]{complex/figures/limit_theorem}
\caption{Contours for big and small limit theorems.}
\label{fig-limit-theorem}
\end{marginfigure}

This is called the big limit theorem. Important: do not confuse when to use Jordan's lemma and when to use the big limit theorem (look for the presence of an exponential). Also do not confuse when to add a factor $z-a$ to the limit related to $f(z)$.

Similarly, there is also a small limit theorem. Indeed, for a circular contour spanning an angle $\alpha$ with top at $z=a$ (see Fig.~\ref{fig-limit-theorem}), we have that if

\begin{equation}
\lim_{z \to a}  f(z) (z-a) = A
\end{equation}
then
\begin{equation}
\lim_{R \to 0} \int_{{C}_R} f(z) dz = j \alpha A
\end{equation}

\begin{exer}
  % difficulty: hard
  % youtube: kv1-JzPvAwI
  Prove the small limit theorem for the special case where $f(z)$ has a single pole at $z=a$.
  \begin{hnt}
    Integrate the Laurent series term by term.
  \end{hnt}
\end{exer}

\pagebreak

\subsectionyoutube{Cauchy principal value}{mFuidtXCRDo}

\begin{marginfigure}
\centering
\includegraphics[width=4cm]{complex/figures/pv}
\caption{The function $1/x$.}
\label{fig-pv}
\end{marginfigure}

Let's discuss a final technicality that will come handy in some cases. Consider the integral $\int_0^1 dx / x$ (see Fig.~\ref{fig-pv}). As the area under this curve is infinite, this integral clearly diverges.

Strictly speaking, the same is true for the integral $\int_{-1}^1 dx / x$, as by definition, this should be seen as

\begin{equation}
\lim_{\epsilon_1 \to 0} \int_{-1}^{-\epsilon_1} \frac{dx}{x} + \lim_{\epsilon_2
\to 0} \int_{\epsilon_2}^1 \frac{dx}{x}
\end{equation}  

Because each term diverges separately, and the limits are taken independently, the whole integral diverges. 

However, Fig.~\ref{fig-pv} suggests that both singularities will cancel out if approached symmetrically. Mathematically, this means that

\begin{equation}
\lim_{\epsilon \to 0} \int_{-1}^{-\epsilon} \frac{dx}{x} + \lim_{\epsilon \to 0}
\int_{\epsilon}^1 \frac{dx}{x} = 0 \label{eq-pv}
\end{equation}  

if both limits are taken at the same time. This is written succinctly as

\begin{equation}
PV \int_{-1}^1 \frac{dx}{x} = 0
\end{equation} 

where $PV$ stands for the Cauchy \emph{principal value} and represents the balancing process of Eq.~\ref{eq-pv}. However, $\int_{-1}^1 dx / x$ still diverges for reasons mentioned above.

The same balancing process can also be applied to limits at infinity:

\begin{equation}
PV \int_{-\infty}^\infty f(x) dx = \lim_{a \to \infty} \int_{-a}^{a} f(x) dx
\end{equation} 

In summary, if you have an integral, it can either converge or diverge. In case the integral diverges, you can look at the principle value of the integral, which in turn can again diverge or not.

\pagebreak

\sectionugent{Evaluation of real--valued integrals}

Now we have all the necessary tools in our box to tackle the important problem
of calculating real--valued integrals by means of complex contour integration.
We will present a number of examples which illustrate some typical techniques
used in this respect.

\subsectionyoutube{Example 1: integrals of the type $\int_0^{2 \pi} f(\cos \theta, \sin \theta) d \theta$}{OsbsS8c6HlA}

Consider integrals of the type

\begin{equation}
\int_0^{2 \pi} f(\cos \theta, \sin \theta) d \theta \label{eq-cont-int-1}
\end{equation} 

By letting $z=e^{j \theta}$, we get 

\begin{equation}
\cos \theta = \frac{z + 1/z}{2}
\end{equation} 

\begin{equation}
\sin \theta = \frac{z - 1/z}{2j}
\end{equation} 

Also, $dz = j e^{j \theta} d \theta = j z d \theta$, so
\begin{equation}
d \theta = \frac{1}{j}\frac{dz}{z}
\end{equation} 

such that the integral Eq.~\ref{eq-cont-int-1} becomes

\begin{equation}
-j \oint_{{C}} f\left(\frac{z + 1/z}{2}, \frac{z - 1/z}{2j}\right)
\frac{dz}{z}
\end{equation} 

The integration contour ${C}$ is the unit circle, and the integral can easily be evaluated using the residue theorem.

As an example, we will calculate

\begin{equation}
I = \int_0^{2 \pi} \frac{d \theta}{1 + \epsilon \cos \theta}, \hspace{0.5cm}
|\epsilon| < 1
\end{equation} 

\begin{cue}
Transform this to a complex contour integral.
\end{cue}

This transforms into

\begin{equation}
I = -j \oint_{{C}} \frac{1}{1 + (\epsilon / 2)\left(z + 1/z\right)}
\frac{dz}{z}
\end{equation} 

Bringing out $j$ and $\epsilon / {2}$ in front of the integral, we get

\begin{equation}
  I = -\frac{2j}{\epsilon} \oint_{{C}} \frac{dz}{\left((2 / \epsilon) + z +
  1/z \right) z}
\end{equation} 

or

\begin{equation}
I = -\frac{2j}{\epsilon} \oint_{{C}} \frac{dz}{z^2 + (2 / \epsilon)z +
1}
\end{equation} 

\begin{cue}
  Where are the poles of this function? Which ones are relevant for us?
\end{cue}

The poles of this function are

\begin{equation}
z = - \frac{1}{\epsilon} \pm \sqrt{ \frac{1}{\epsilon^2} - 1} = - \frac{1}{\epsilon} \pm \frac{1}{\epsilon} \sqrt{1 - \epsilon^2}
\end{equation} 

Only the pole with the plus sign lies within the unit circle, as can be verified e.g. by a series expansion for small values of $\epsilon$:

\begin{equation}
z \approx - \frac{1}{\epsilon} \pm  \frac{1}{\epsilon} \left(1 - \frac{\epsilon^2}{2} \right)
\end{equation} 

The plus sign gives us the value $-\epsilon / 2$, which lies inside the contour given that $|\epsilon| < 1$. The minus sign gives roughly $-2/\epsilon$, outside of the contour.

\begin{cue}
Now calculate the residue and combine everything to calculate the original integral.
\end{cue}

By using the formula from Ex. \ref{ex-res1} to calculate the residue for the pole with plus sign, we get

\begin{equation}
I = 2 \pi j \cdot \frac{-2j}{\epsilon} \cdot \left[\frac{1}{z - (-\frac{1}{\epsilon} -
\frac{1}{\epsilon} \sqrt{1 - \epsilon^2})}\right]_{z = - \frac{1}{\epsilon} +
\frac{1}{\epsilon} \sqrt{1 - \epsilon^2}}
\end{equation}

or

\begin{equation}
I = 2 \pi j \cdot \frac{-2j}{\epsilon} \cdot \frac{1}{\frac{2}{\epsilon} \sqrt{1
- \epsilon^2}}
\end{equation}

So finally

\begin{equation}
\int_0^{2 \pi} \frac{d \theta}{1 + \epsilon \cos \theta} = \frac{2 \pi}{\sqrt{1
- \epsilon^2}}, \hspace{0.5cm} |\epsilon| < 1
\end{equation} 
 

\pagebreak

\subsectionyoutube{Example 2: integrals of the type $\int_{-\infty}^{\infty} f(z) e^{jbz} dz$}{cV9ArgoI7KU}

Let's calculate

\begin{equation}
\int_0^{\infty}\frac{\cos \lambda x}{1 + x^2} dx, \hspace{0.5cm} \lambda > 0
\end{equation}

\noindent\marginnote{Alternatively, we could have made use of $\cos z = (e^{j z} + e^{-jz})/2$, but then Jordan's lemma would have required two separate integrals for each of the complex exponentials, each with a different contour.}To do this, we will calculate the real part of the following contour integral (Fig.~\ref{fig-example-2}), and take the limit of $R$ going towards infinity:

\begin{equation}
I = \oint_{{C}} \frac{e^{j \lambda z}}{1 + z^2} dz
\end{equation}

\begin{marginfigure}
\centering
\includegraphics{complex/figures/int_ex_2}
\caption{Contour for example 2.}
\label{fig-example-2}
\end{marginfigure}

Evaluating the part of this contour on the positive real axis, and then taking the real part will recover the required cosine in the integral. It is true that we are only interested in the contribution from the positive real axis, but as you'll see, we'll be able to deal with the other contributions in due course.

\begin{cue}
Use residue calculus to evaluate the contour integral.
\end{cue}

The only pole enclosed by the contour is at $j$, with residue $e^{-\lambda}/(j+j)$, such that the residue theorem leads to 

\begin{equation}
  I = \oint_{{C}} \frac{e^{j \lambda z}}{1 + z^2} dz = 2 \pi j \mathrm{Res}_{j} =  2 \pi j \frac{e^{-\lambda}}{2j} = \pi e^{-\lambda}
\end{equation}

Let's also split our contour into the straight part and the semicircle:

\begin{equation}
\int_{-R}^{R} \frac{e^{j \lambda x}}{1 + x^2} dx + \int_{{C_R}}
\frac{e^{j \lambda z}}{1 + z^2} dz = \pi
e^{-\lambda}
\end{equation}

On the real axis, we can indeed replace $z$ by $x$ again. Let's now take the limit $R \to \infty$ and study the different contributions to the contour.

\begin{cue}
Can we apply Jordan's lemma to ${C_R}$? 
\end{cue}

\noindent\marginnote[0.5cm]{Don't include a factor $z-0$ here, this is not the big limit theorem!}If $\lambda > 0$, the contour lies indeed in the 'proper' part of the complex plane. For the second condition, we need to calculate the following limit:

\begin{equation}
\lim_{z \to \infty}\frac{1}{1+z^2} = \lim_{z \to \infty}\frac{1}{1+|z|^2 e^{2 j
\arg z}}
\end{equation}

Since $e^{2 j \arg z}$ always stays bounded, this limit goes to zero for all directions in the complex plane. So, we can apply Jordan's lemma and the contribution from ${C_R}$ vanishes.

\begin{cue}
Write down what remains of the contour integral and use this to calculate our original real-valued integral.
\end{cue}

After taking the limit $R \to \infty$, we're only left with

\begin{equation}
PV \int_{-\infty}^{\infty}\frac{e^{j \lambda x}}{1 + x^2} dx = \pi e^{-\lambda}
\end{equation}

\noindent\marginnote[-1.5cm]{For readers that like to lie awake at night about mathematical rigour: we do indeed need to mention `principle value` here, since the fact that we're using a circle centered at the origin, means that we approach  $\pm \infty$ together in a symmetric way.}After taking the real part of the result, we get

\begin{equation}
PV \int_{-\infty}^{\infty}\frac{\cos \lambda x}{1 + x^2} dx = \pi e^{-\lambda}
\end{equation}

Finally, due to the even character of the integrand, we arrive at

\begin{equation}
\int_0^{\infty}\frac{\cos \lambda x}{1 + x^2} dx = \frac{\pi}{2} e^{-\lambda}
\end{equation}

\pagebreak

\subsectionyoutube{Example 3: integrals with branch cuts}{KZ8rFoVzP34}

Let's now try an example with branch point singularities:

\begin{equation}
\int_0^{\infty}\frac{\sqrt{x}}{x^2+a^2}dx, \hspace{0.5cm} a > 0
\end{equation}

\begin{marginfigure}[-0.9cm]
\centering
\includegraphics{complex/figures/int_ex_3}
\caption{Contour for example 3.}
\label{fig-example-3}
\end{marginfigure}

We stick to the traditional choice of branch cut, namely the negative real axis (Fig.~\ref{fig-example-3}). The contour is placed 'just above' this branch cut. To be on the safe side, in order to avoid the branch point at $z=0$, we also make a small detour around the origin.

\begin{cue}
Use residue calculus to evaluate the contour integral.
\end{cue}

\noindent\marginnote{$ja$ is a single pole obviously, and not a branch point, as it has nothing to do with the factor $z^{1/2}$.}The only singularity inside the contour is $ja$.
\begin{align}
I = \oint_{{C}} \frac{z^{1/2}}{z^2+a^2} dz =& \, 2 \pi j \textrm{Res}_{j a}
\nonumber \\
=& \, 2 \pi j \frac{(j a)^{1/2}}{ja + ja} \nonumber \\
=& \, \pi \frac{\sqrt{a}\left(e^{j\frac{\pi}{2}}\right)^{1/2}}{a} \nonumber \\
=& \, \frac{\pi}{\sqrt{a}} e^{j \pi /4}
\end{align}

We used the traditional choice of branch cut, and it's easy to verify that $e^{j \pi /4}$ is indeed in the right half plane $\Re w > 0$.

\begin{cue}
What is the contribution of ${C_R}$ to the integral in the limit of infinite radius?
\end{cue}

\noindent\marginnote[0.5cm]{Don't forget the factor $z-0$ here!}Let's use the big limit theorem to calculate the contribution of the outer circular part ${C_R}$ to the integral. For that, we calculate the following limit:

\begin{equation}
\lim_{z \to \infty}\frac{z^{1/2}}{z^2+a^2} \cdot (z - 0) = \lim_{z \to
\infty}\frac{\sqrt{|z|}e^{j \arg z / 2}}{|z|^2 e^{2 j \arg z}+a^2} \cdot |z|
e^{j \arg z}
\end{equation}

Just as before, the complex exponentials involving $\arg z$ always stay bounded, so this limit goes to zero and the contribution from this part of the contour vanishes.

\begin{cue}
What is the contribution of the small inner circle $\gamma$ to the integral in the limit of zero radius?
\end{cue}

Similarly, we use the small limit theorem to show that the contribution for the semicircle around the branch point vanishes in the limit of zero radius:

\begin{equation}
\lim_{z \to 0}\frac{z^{1/2}}{z^2+a^2} \cdot z = \frac{0}{a^2} = 0
\end{equation}

So, the branch point does not contribute to the integral.

\begin{cue}
Write down what remains of the contour integral and use this to calculate our original real-valued integral.
\end{cue}

We are left with

\begin{equation}
I = \int_{- \infty}^{0}\frac{z^{1/2}}{z^2+a^2}dz + \int_{0}^{\infty}\frac{z^{1/2}}{z^2+a^2}dz
\end{equation} 

Returning from $z$ to $x$, we get with our choice of branch cut (see the calculation of $w_+$ in the section on branch cuts, for points just above the negative real axis) that

\begin{equation}
z^{1/2} = 
\begin{cases}
\sqrt{x}, & x > 0\\
j \sqrt{-x}, & x < 0
\end{cases}
\end{equation} 

such that

\begin{align}
I = & \int_{- \infty}^{0}\frac{j\sqrt{-x}}{x^2+a^2}dx +
\int_{0}^{\infty}\frac{\sqrt{x}}{x^2+a^2}dx \nonumber \\
 = & \, (j + 1) \ \int_{0}^{\infty}\frac{\sqrt{x}}{x^2+a^2}dx \nonumber \\
 = & \, \frac{\pi}{\sqrt{a}} e^{j \pi /4} = \, \frac{\pi}{\sqrt{a}} \frac{1+j}{\sqrt{2}}
\end{align} 

where in the last line we just recap the result of the residue calculus. So finally

\begin{equation}
\int_0^{\infty}\frac{\sqrt{x}}{x^2+a^2}dx = \frac{\pi}{\sqrt{2a}}
\end{equation}

\pagebreak

\begin{exer}
% difficulty: trivial
% ugent
% youtube: v09NSxfVNY0
  \label{ex-contour-integral-1}
Use complex contour integration to calculate
$$\int_0^{\infty} \frac{dx}{1+x^2}$$
\begin{sol}
$$\frac{\pi}{2}$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: trivial
  % youtube: YhbD-ye_RTE
Repeat Ex.~\ref{ex-contour-integral-1}, but show that you get the same result if you close the contour in a different half plane.
\end{exer}

\begin{exer}
% difficulty: trivial
% ugent
% youtube: 3RJv9Nf1lts
  Comment on the suitability of the following contours for calculating
  $$ \int_0^{\infty} \frac{\sin x}{x} dx$$

(All of these were harvested from actual students trying their hand at this problem.)

\begin{center}
\includegraphics[width=10cm]{complex/figures/contours}
\end{center}

\end{exer}

\pagebreak

\begin{exer}
% difficulty: normal
% ugent
% youtube: _DBoH63WDGk 
Use complex contour integration to calculate
$$ \int_0^{\infty} \frac{\sin x}{x} dx$$
\begin{sol}
$$\frac{\pi}{2}$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: 46bqZ-w-rSI
Use complex contour integration to calculate
$$ \int_0^{\infty} \frac{1}{\left(x^2 + a^2\right)^2} dx$$
Here $a$ is a positive real-valued number.
\begin{sol}
$$\frac{\pi}{4 a^3}$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: tQnHZ3Oa4XI
Use complex contour integration to calculate
$$ \int_{-\infty}^{\infty} \frac{\sin \pi x}{x (x-1) (x-2)} dx$$
\begin{sol}
$$2 \pi$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: normal
 % youtube: PudvMdmpljw 
Use complex contour integration to calculate
$$ \int_0^{2\pi} \frac{\cos^2 \theta d \theta}{13-5\cos 2 \theta}$$
\begin{sol}
$$\frac{\pi}{10}$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: hard
  % youtube: K6vOAX72XwM 
Use complex contour integration to calculate
$$ \int_0^\pi \sin^{2n} \theta d \theta$$
Here, $n \ge 1$.
\begin{sol}
$$\frac{(2n)!}{ 2^{2n}(n!)^2} \pi$$
\end{sol}
\end{exer}

\begin{exer}
  % difficulty: hard
  % youtube: xwUzDDkHVnY
Use complex contour integration to calculate
$$ \int_0^\infty \frac{x ^ {2m}}{x^{2n} + 1} dx$$
Here $m$ and $n$ are integers and $0 \le m < n$.
\begin{sol}
$$\frac{\pi}{2n} \mathrm{cosec} \left( \frac{2m+1}{2n} \pi \right)$$
\end{sol}
\end{exer}


\pagebreak


\sectionugent{Application: Kramers--Kronig dispersion relations}

\subsectionyoutube{Kramers--Kronig and the Hilbert Transform}{zJCcXXN4dM4}

Suppose $f(z)$ is an analytic function with $\lim_\infty f(z) = 0$ in the upper half of the complex plane.

\begin{marginfigure}[-0.5cm]
\centering
\includegraphics{complex/figures/kk}
\caption{Contour for Kramers--Kronig dispersion relations.}
\label{fig-KK}
\end{marginfigure}

Applying Cauchy's theorem to the contour in Fig.~\ref{fig-KK} leads to

\begin{equation}
\oint_{{C}} \frac{f(z)}{z-x_0} dz = 0
\end{equation}

\begin{cue}
Split up the contour integral into contributions from its different parts.
\end{cue}

\begin{marginfigure}[1.0cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/Hans_Kramers
  \includegraphics[]{complex/figures/h_kramers}
  \caption{Hans Kramers (1894–1952)}
\end{marginfigure}

The integral over the large semi--circle vanishes because of the big limit theorem, because of the requirement that $\lim_\infty f(z) = 0$ in the upper half of the complex plane, so

\begin{equation}
  \lim_{z \to \infty} \frac{f(z)}{z-x_0} \cdot (z-x_0) = 0
\end{equation}

For the contribution of the small semi--circle around the pole $x_0$ we could use the small limit theorem, or alternatively calculate it directly using the parametrisation $z=x_0 + \epsilon e^{j \theta}$:

\begin{equation}
\lim_{\epsilon \to 0} & \int_{\pi}^0 \frac{f(x_0+\epsilon e^{j \theta})}{\epsilon e^{j\theta}} \epsilon j e^{j \theta} d \theta = j f(x_0) \int_{\pi}^{0} d \theta= -j \pi f(x_0)
\end{equation}

This leads to 
\begin{equation}
\lim_{\epsilon \to 0} & \int_{- \infty}^{x_0-\epsilon} \frac{f(x)}{x-x_0}dx -j \pi f(x_0) + \lim_{\epsilon \to 0} \int_{x_0+\epsilon}^{\infty} \frac{f(x)}{x-x_0}dx = 0
\end{equation} 

or 

\begin{equation}
f(x_0) = \frac{1}{\pi j} PV \int_{- \infty}^{\infty} \frac{f(x)}{x-x_0}dx
\label{eq-kk-1}
\end{equation} 

If you squint a bit, you could say that the singularity $x_0$ lies more or less on our contour (although we avoided it with the small semicircle). You could therefore say that it's halfway between a singularity outside of the contour (Cauchy's theorem) and one inside the contour (Cauchy's formula). This is also reflected in the result of the integral, which is the average of these two cases, with an extra principal value thrown in for good measure.

\begin{exer}
  % difficulty: trivial
  % youtube: lSqZlxCTX-s
Show that Eq.~\ref{eq-kk-1} can also be obtained by choosing a contour that circles around $x_0$ in the lower half of the complex plane.
\end{exer}

\begin{cue}
Split up Eq.~\ref{eq-kk-1} into its real and imaginary parts to derive expressions for $ u(x_0)= \Re f(x_0)$ and $ v(x_0)= \Im f(x_0)$.
\end{cue}

\begin{marginfigure}[-1.5cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/Ralph_Kronig
  \includegraphics{complex/figures/r_kronig}
  \caption{Ralf Kronig (1904–1995)}
\end{marginfigure}

Splitting Eq.~\ref{eq-kk-1} into real and imaginary parts yields

\begin{align}
f(x_0) =& \, u(x_0) + jv(x_0) \nonumber \\
       =& \, \frac{1}{\pi j} PV \int_{- \infty}^{\infty} \frac{u(x)+jv(x)}{x-x_0}dx
 \nonumber \\
       =& \, \frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{v(x)}{x-x_0}dx -
\frac{j}{\pi} PV \int_{- \infty}^{\infty} \frac{u(x)}{x-x_0}dx
\end{align}

or

\begin{subequations} 
\begin{equation}
u(x_0) = \frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{v(x)}{x-x_0}dx
\end{equation} 
\begin{equation}
v(x_0) = -\frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{u(x)}{x-x_0}dx
\end{equation}
\label{eq-KK}
\end{subequations}

\begin{marginfigure}[-1.5cm]
  % credits: Wikipedia
  % url: https://en.wikipedia.org/wiki/David_Hilbert
  \includegraphics{complex/figures/d_hilbert}
  \caption{David Hilbert (1862–1943)}
\end{marginfigure}

Equations \ref{eq-KK} are called the \emph{Kramers--Kronig} dispersion relations. They state that under the conditions given above, the real part of a function can be expressed as an integral over the imaginary part and vice--versa.

By definition, equations \ref{eq-KK} also express that the real and imaginary parts are \emph{Hilbert transforms} of each other. Hilbert transforms also find use in e.g. telecommunications.


\pagebreak

\subsectionyoutube{Kramers--Kronig applied to photonics}{4SFkLiSKhxs}

Let's now apply the Kramers--Kronig relations to the field of material dispersion in photonics.

As a choice of complex function, let's first consider $f(z) = \chi(\omega) =
n^2(\omega) -1$. As you know, $\chi(\omega)$ is a material's susceptibility and relates the polarisation $\mathbf{P}$ to the incident electric field $\mathbf{E}$ according to $\mathbf{P}(\omega)=\varepsilon_0 \chi(\omega) \mathbf{E}(\omega)$ in the frequency domain.

\begin{cue}
What is the mathematical reason we use $f(z) = \chi(\omega)$ here, and not e.g. $f(z) = n(\omega)$? Link this to the physics of the problem. 
\end{cue}

Remember that at $z=\infty$, i.e at infinite frequencies $\omega$, $f$ should approach zero in order for the Kramers-Kronig relations to hold. When excited with a field with infinite frequency, the electrons in a material will no longer be able to follow the oscillations of the driving field and simply stop moving. In effect, the material stops interacting with its environment, and it will be as if it is no longer there, i.e. it will behave as vacuum. This means that at infinite frequencies, its refractive index will be 1 and its susceptibility will be 0, as required.

Let's now replace $x_0$ by $\omega$, and $x$ by $\omega'$, so that we get

\begin{subequations} 
\begin{equation}
\Re \chi(\omega) = \frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{\Im
\chi(\omega')}{\omega'-\omega}d\omega'
\end{equation} 
\begin{equation}
\Im \chi(\omega) = -\frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{\Re
\chi(\omega')}{\omega'-\omega}d\omega'
\end{equation}
\label{eq-KK-2}
\end{subequations}

\begin{cue}
Can you think of an alternative choice for $f(z)$, one that will give us information related to $n$ rather than to $n^2$?
\end{cue}

If we use $f(z)= \Delta n(\omega) = n(\omega) - n(\infty) = n(\omega) - 1$, we also satisfy the conditions of the Kramers-Kronig relations, and now we get

\begin{subequations} 
  \begin{equation}
  \Re \Delta n(\omega) = \frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{\Im
  \Delta n(\omega')}{\omega'-\omega}d\omega'
  \end{equation} 
  \begin{equation}
  \Im \Delta n(\omega) = -\frac{1}{\pi} PV \int_{- \infty}^{\infty} \frac{\Re
  \Delta n (\omega')}{\omega'-\omega}d\omega'
  \end{equation}
  \label{eq-KK-3}
  \end{subequations}

As you might remember, the imaginary part of the refractive index $n$ is a measure for optical absorption. So, this means that in theory it is enough to measure just the losses of a material over a wide wavelength range to calculate its refractive index.

Finally, it's important to note that one can prove that there is a relation between the Kramers--Kronig dispersion relations and the fact that the systems considered are \emph{causal} (i.e. effect cannot precede cause)\noindent\marginnote{This is one of the subjects of the Titchmarsh theorem.}. Thus, there is an immediate physical significance of the Kramers--Kronig dispersion relations.

\begin{exer}
  % difficulty: hard
  % youtube: Goi6ApUWzbQ 

Recall the definition of the susceptibility in the time domain:

\begin{equation}
\mathbf{P}(t)=\varepsilon_0 \int_{-\infty}^t \chi(t-t') \mathbf{E}(t')\, dt'.
\end{equation}

From this, we can easily see that $\chi(t)$ is necessarily real, because complex numbers only show up in the frequency domain after the introduction of phasors. 

Use this to show that the Kramers--Kronig dispersion relations can also be written as

$$\Re \chi(\omega) =  \frac{2}{\pi} PV \int_{0}^{\infty}{ \frac{\omega'\Im \chi(\omega')}{\omega'^2-\omega^2}d\omega'}$$
$$\Im \chi(\omega) = -\frac{2}{\pi} PV \int_{0}^{\infty}{ \frac{\omega \Re \chi(\omega')}{\omega'^2-\omega^2}d\omega'}$$

Obviously, similar expressions hold for $\Delta n$.

  \begin{hnt}
    Show that $\chi(-\omega) = \chi^*(\omega)$, and figure out whether $u(\omega)$ and $v(\omega)$ are even or odd, and split up the integral in contributions for positive and negative frequencies.
  \end{hnt}
\end{exer}

\begin{exer}
  % difficulty: normal
  % youtube: lYT8UXHY9RM
Suppose you have a material without dispersion, i.e. where the real part of the refractive index is constant. Show that such a material is lossless, i.e. the imaginary part of the refractive index is zero.
\end{exer}

\begin{exer}
  % difficulty: trivial
  % youtube: 0zeDCIXKRtU
From basic logic and the result above, conclude that as soon as you have loss in a material, the material is necessarily dispersive.
\end{exer}

\begin{exer}
  % difficulty: trivial
  % youtube: HoBmzkpdgFo
Show that the only non-dispersive medium is vacuum.
\end{exer}


\pagebreak


\sectionugent{Conformal transformations}
\label{week3}

\subsectionyoutube{Angle--preserving transformations}{x-OiLCxJJSM}

\begin{marginfigure}
\centering
\includegraphics{complex/figures/conformal_portrait}
\caption{Conformal transformation.}
\label{fig-conformal}
\end{marginfigure}

A complex function $w = f(z) = u(x,y)+jv(x,y)$ can be seen as a mapping from the complex $z$--plane to the complex $w$--plane. One way to visualise this is to plot how a curve $C_z$ in the $z$--plane is transformed to a curve $C_w$ in the $w$--plane (see Fig.~\ref{fig-conformal}).

We can play this transformation game using two specific neighbouring points on $C_z$, e.g. $z_0$ and $z_0+\Delta z$. They get transformed to two neighbouring points on $C_w$, which we'll call imaginatively $w_0$ and $w_0+\Delta w$. In the limit of $\Delta z \to 0$, this will allow us to say something about the relationship between the tangents to these curves at the points $z_0$ and $w_0$.

\begin{cue}
Relate $\frac{df}{dz}$ to $\Delta z$ and $\Delta w$. Then look at the angles (arguments) of the resulting expression to determine how the tangents rotate.
\end{cue}

As long as $w=f(z)$ is an analytic function, we have

\begin{equation}
\frac{df}{dz} = \frac{dw}{dz} = \lim_{\Delta z \to 0} \frac{\Delta w}{\Delta z}
\end{equation}

By looking at the argument of this equation, we can derive an expression relating the angles/arguments of the tangents at $z_0$ and $w_0$:

\begin{equation}
\arg \frac{df}{dz} = \arg \lim_{\Delta z \to 0} \frac{\Delta w}{\Delta z} = \arg
\lim_{\Delta z   \to 0} \Delta w - \arg \lim_{\Delta z \to 0} \Delta z
\label{eq-angle-transform}
\end{equation} 

For an analytic function $\arg df / dz = \alpha$ (the angle of the derivative) depends on $z$, but for a given $z$ it is independent of the direction of approach. So, if in Fig.~\ref{fig-conformal} the angle of the increment $\Delta z$ with respect to the $x$--axis is $\theta$, and the increment $\Delta w$ forms an angle $\phi$ with the $u$ axis, Eq.~\ref{eq-angle-transform} becomes $\alpha = \phi - \theta $, or

\begin{equation}
\phi = \theta + \alpha
\end{equation}

This also means that an analytic transformation will rotate any curve through $z_0$ in the $z$--plane over an angle of $\alpha$ in the $w$--plane. Since this result holds for any curve through $z_0$, it obviously also holds for any \emph{pair} of curves. This means that for the angle between these two curves we get

\begin{equation}
\phi_2 - \phi_1 = (\theta_2 + \alpha) - (\theta_1 + \alpha) = \theta_2 -
\theta_1
\end{equation} 

From this we can see that such a transformation preserves the angle between any pair of curves. Such an angle--preserving transformation defined by an analytic function is called a \emph{conformal transformation}.

\subsectionyoutube{Conformal transformations and the Helmholtz equation}{UHCrs6w2140}

Conformal transformations can be useful to solve the Helmholtz equation in a 'difficult' situation. The idea is to use a conformal mapping to move to a different domain, where the solution is more tractable. In this section, we will investigate what form the Helmholtz equation takes in the new domain.

Suppose our original Cartesian $(x,y)$--coordinate system is related to a new $(u,v)$--coordinate system by a conformal transformation $f$:

\begin{equation}
u+jv = w = f(z) = f(x+jy)
\end{equation} 

In the $z$--plane, the Helmholtz equation in media with piecewise constant refractive index has the following form:

\begin{equation}
\frac{\partial^2 \psi(x,y)}{\partial x^2} + \frac{\partial^2 \psi(x,y)}{\partial y^2} + k_0^2 n^2(x,y) \psi(x,y) = 0
\end{equation}

\begin{cue}
Think of $\psi$ as $\psi\left(u(x,y), v(x,y)\right)$. Use the chain rule to express $\frac{\partial \psi}{\partial x}$ using partial derivatives with respect to $u$ and $v$.
\end{cue}

\noindent\marginnote{If you're a bit confused about what's really going on here, e.g. in terms of arguments to the functions, watch the video.}Application of the chain rule leads to

\begin{equation}
\frac{\partial \psi}{\partial x} = \frac{\partial \psi}{\partial u}
\frac{\partial u}{\partial x} + \frac{\partial \psi}{\partial v} \frac{\partial
v}{\partial x}
\end{equation} 


\begin{cue}
Now calculate $\frac{\partial^2 \psi}{\partial x^2}$.
\end{cue}

For the second derivative this becomes

\begin{equation}
\frac{\partial^2 \psi}{\partial x^2} = \frac{\partial}{\partial x} \left[
\frac{\partial \psi}{\partial u}\right]  \frac{\partial u}{\partial x} +
\frac{\partial \psi}{\partial u}\frac{\partial^2 u}{\partial x^2} +  
\frac{\partial}{\partial x} \left[ \frac{\partial \psi}{\partial v}\right] 
\frac{\partial v}{\partial x}  + \frac{\partial \psi}{\partial
v}\frac{\partial^2 v}{\partial x^2}
\end{equation} 

Or

\begin{align}
\frac{\partial^2 \psi}{\partial x^2} = &\left[ \frac{\partial^2 \psi}{\partial u^2 } \frac{\partial u}{\partial x} +  \frac{\partial^2 \psi}{\partial u \partial v} \frac{\partial v}{\partial x} \right] \frac{\partial u}{\partial x}  + \frac{\partial \psi}{\partial u}\frac{\partial^2 u}{\partial x^2} \nonumber \\ 
+ &\left[ \frac{\partial^2 \psi}{\partial v^2 } \frac{\partial v}{\partial x} + 
\frac{\partial^2 \psi}{\partial u \partial v} \frac{\partial u}{\partial x}
\right] \frac{\partial v}{\partial x} + \frac{\partial \psi}{\partial v}\frac{\partial^2 v}{\partial x^2}
\end{align} 

\begin{cue}
Now add these two second-order derivatives, as required for the Laplacian. Then, go on a term-cancelling spree, remembering that the Cauchy-Riemann conditions hold. Also, note that for a holomorphic function $\nabla^2 u = \nabla^2 v=0$.
\end{cue}

For the total Laplacian we get

\begin{align}
\frac{\partial^2 \psi}{\partial x^2} &+ \frac{\partial^2 \psi}{\partial y^2}= \nonumber \\
  &\frac{\partial^2 \psi}{\partial u^2 }  \left [ \left(\frac{\partial u}{\partial x}\right)^2 + \left(\frac{\partial u}{\partial y}\right)^2\right] + 2\frac{\partial^2 \psi}{\partial u \partial v} \frac{\partial u}{\partial x} \frac{\partial v}{\partial x}  + \frac{\partial \psi}{\partial u} \left[ \frac{\partial^2 u}{\partial x^2}  + \frac{\partial^2 u}{\partial y^2} \right]   \nonumber \\  
+ &\frac{\partial^2 \psi}{\partial v^2}  \left[ \left(\frac{\partial v}{\partial
x}\right)^2 + \left(\frac{\partial v}{\partial y}\right)^2\right]+  2\frac{\partial^2 \psi}{\partial u \partial v} \frac{\partial u}{\partial y} \frac{\partial v}{\partial y} + \frac{\partial
\psi}{\partial v} \left[ \frac{\partial^2 v}{\partial x^2} + \frac{\partial^2 v}{\partial y^2} \right] 
\label{eq-conf-trans-1}
\end{align} 

It is easy to see that terms two and five cancel because of the Cauchy--Riemann conditions $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} $ and $\frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x}$.

We know from Ex.~\ref{ex-harmonic} that for a holomorphic function $\nabla^2 u =
\nabla^2 v=0$, so the third and the sixth term on the right--hand--side of
Eq.~\ref{eq-conf-trans-1} vanish as well.

\begin{cue}
What does Cauchy--Riemann teach us about the factors in square brackets in terms one and four?
\end{cue}

Because of the Cauchy--Riemann equations, we can write

\begin{equation}
\left(\frac{\partial u}{\partial x}\right)^2 + \left(\frac{\partial u}{\partial
y}\right)^2 = \left(\frac{\partial v}{\partial y}\right)^2  +
\left(\frac{\partial v}{\partial x}\right)^2 
\end{equation} 
\end{equation}

So, the square brackets in terms 1 and 4 are the same. We can also write them as

\begin{equation}
\left(\frac{\partial u}{\partial x}\right)^2 + \left(\frac{\partial u}{\partial
y}\right)^2 = \left(\frac{\partial u}{\partial x}\right)^2 + \left(\frac{\partial v}{\partial
x}\right)^2 
 \stackrel{def}{=} \frac{1}{T^2} \label{eq-T-factor}
\end{equation} 

So finally, we can write the Helmholtz equation in the transformed domain as

\begin{equation}
\frac{\partial^2 \psi(u,v)}{\partial u^2} + \frac{\partial^2 \psi(u,v)}{\partial
v^2} + k_0^2 T^2(u,v)n^2(u,v) \psi(u,v) = 0
\end{equation} 

Formally, this is identical to the Helmholtz equation in the $z$--plane, except that \emph{the index distribution $n$ has been replaced by a transformed index distribution $T \cdot n$}.

Finally, note that what we've done is not just any old coordinate transformation: we really relied on the fact that we were dealing with a holomorphic function here.

\pagebreak

\subsectionyoutube{Application: radiation losses in bent waveguides}{fhIBO7Czxjs}

\begin{marginfigure}[1cm]
\centering
\includegraphics{complex/figures/bends_portrait}
\caption{Calculating bend modes using conformal transformation.}
\label{fig-bends}
\end{marginfigure}

To give an example of the power of a conformal transformation, we will use one to find the eigenmodes of a bent dielectric waveguide (Fig.~\ref{fig-bends}). (We consider the system to be invariant in the third dimension.)

To tackle this problem, we could use a 'traditional' coordinate transformation and move to cylindrical coordinates. In that case, the geometry of the refractive index distribution stays the same, but we just use a more natural coordinate system to describe it. This will obviously change the form of the equation: a Laplacian in cylindrical coordinates looks completely different from one in Cartesian coordinates.

In this section however, we will use a different approach: we will let a conformal transformation loose on the system! As we've seen in the previous section, that leaves the form of the Helmholtz equation intact (it still looks like a Cartesian one), but now the geometry of the refractive index profile changes. 

Although both approaches involve a change of coordinates, their effect and interpretation is different: you could say that one is the dual of the other, in terms of whether it leaves the refractive index geometry or the equation intact.

Let's now see if we can find a holomorphic function that will change the curved geometry to e.g. a straight one, which is easier to deal with. Look at the following conformal transformation, proposed in the 70s\footnote{M. Heiblum and J. Harris, ‘Analysis of curved optical waveguides by conformal transformation’, IEEE Journal of Quantum Electronics, vol. 11, no. 2, pp. 75–83, Feb. 1975.}:

\begin{equation}
w = R_2 \ln \frac{z}{R_2}
\end{equation} 

Here, $R_2$ is the outer radius of the bend.

\begin{cue}
Express this equation in polar coordinates and verify that this straightens the bend.  
\end{cue}

With $z=r e^{j \theta}$, we can write this as

\begin{equation}
u + jv = R_2 \ln \frac{r}{R_2} + j R_2 \theta
\label{eq-con-trans-bend}
\end{equation} 

This clearly shows the effect of the transformation: a circular path in the $z$--plane with constant $r$ is transformed to a straight path in the $w$--plane with constant $u$ (see Fig.~\ref{fig-bends}).

\begin{cue}
Calculate the transformation factor $T$. 
\end{cue}

Using the definition of the transformation factor $T$ from Eq.~\ref{eq-T-factor}, we need to calculate

\begin{align}
\frac{\partial u}{\partial x} &= R_2 \frac{\partial }{\partial x} \left[ \ln \frac{\sqrt{x^2+y^2}}{R_2} \right] \nonumber \\
&= R_2 \frac{R_2}{\sqrt{x^2+y^2}} \cdot \frac{1}{R_2} \cdot \frac{2x}{2\sqrt{x^2+y^2}} = R_2 \frac{x}{x^2+y^2}
\end{align} 

Also,

\begin{equation}
\frac{\partial v}{\partial x} = R_2 \frac{\partial}{\partial x} \arctan
\frac{y}{x} = \frac{R_2}{1 + \frac{y^2}{x^2}} \cdot y \cdot \frac{-1}{x^2}= -R_2
\frac{y}{x^2+y^2}
\end{equation} 

So finally

\begin{equation}
T = \frac{1}{\sqrt{u_x^2+v_x^2}} = \frac{1}{R_2 \sqrt{\frac{x^2+y^2}{(x^2+y^2)^2}}} = \frac{\sqrt{x^2+y^2}}{R_2} = \frac{r}{R_2}
\end{equation} 

But since from Eq.~\ref{eq-con-trans-bend}, $\frac{u}{R_2}=\ln{\frac{r}{R_2}}$, we have that 

\begin{equation}
T = \frac{r}{R_2} = e^{\frac{u}{R_2}}
\end{equation} 

So, in the new coordinate system, the transformed index profile looks like

\begin{equation}
n_t(u) = n(u)e^{\frac{u}{R_2}}
\end{equation} 

This profile is sketched in Fig.~\ref{fig-bends}. To find the modes of this straight waveguide with its complicated index profile, we proceed as follows: first, the continuous index profile is approximated by a stepwise constant profile with a large number of steps. Then, the modes of such a multilayered waveguide can be readily found using standard techniques (numerical, or approximated analytical).

When this way of calculating the modes of a bent waveguide was first proposed in the 1970s, the calculation power of computers was nothing to write home about, so any trick that could simplify a problem was very welcome. Today, the importance of these techniques is more pedagogical than practical. It does allow us to get some physical insight, though:

\begin{cue}
Making use of the tendency of light to be concentrated in regions with high refractive index, think about how light in these bent waveguides will behave. One which side of the waveguide will the intensity be highest? What about loss due to the bend? 
\end{cue}

Because the refractive index is higher near the outside of the bend, the mode will tend to be concentrated there. As you can see from the transformed index profile, there is even the risk that the light tunnels towards the outer cladding, where the index is even higher. This leakage mechanism is a nice way to explain the origin of the radiation losses in waveguide bends. 

\begin{cue}
What happens if the radius of curvature increases or decreases?
\end{cue}    

Physically, it makes sense that for large radii $R_2$, the bend will be straightened out, and the radiation losses will go down.

It is tempting to support this mathematically using the following argument: tighter bends (i.e. shorter radii $R_2$) will be more lossy, because $T=e^{\frac{u}{R_2}$ becomes a steeper exponential, which will reduce the tunneling distance and increase the leakage.

\begin{cue}
What's missing in that argument? What would happen e.g. if you had simply used the transformation $w=\ln z$, which does not even depend on $R_2$?
\end{cue}

Looking at the steepness of the index profile in the cladding only tells part of the story. There are also aspects like how wide the waveguide becomes after transformation, how big is the index in the core, ... . So, it's the entire index profile that will determine the radiation losses, not just the steepness in the outer cladding.

\pagebreak

\section*{Review questions}

\begin{itemize}
\item What is a holomorphic function?
\item What are the Cauchy-Riemann conditions?
\item What is Cauchy's theorem?
\item What is Cauchy's formula?
\item What is a Laurent series?
\item What type of poles can a function have?
\item What are branch points and branch cuts?
\item What is the Riemann surface?
\item What is a residue?
\item How do you calculate the residue of a single pole?
\item What is the residue theorem?
\item What is Jordan's lemma?
\item What are the big and small limit theorems?
\item What is the principal value of an integral?
\item How do you solve integrals of the type $\int_0^{2 \pi} f(\cos \theta, \sin \theta) d \theta$?
\item How do you solve integrals of the type  $\int_\infty^{\infty} f(z) e^{jbz} dz$?
\item What do the Kramers-Kronig relations express?
\item What are conformal transformations and what are they used for?
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
